 This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x = x.reshape(b, n, num_heads, c // num_heads)
Unsupported operator aten::sub encountered 138 time(s)
Unsupported operator aten::div encountered 422 time(s)
Unsupported operator aten::rsub encountered 58 time(s)
Unsupported operator aten::add encountered 275 time(s)
Unsupported operator aten::add_ encountered 64 time(s)
Unsupported operator aten::mul encountered 425 time(s)
Unsupported operator aten::softmax encountered 39 time(s)
Unsupported operator aten::gelu encountered 34 time(s)
Unsupported operator aten::mean encountered 6 time(s)
Unsupported operator aten::pow encountered 3 time(s)
Unsupported operator aten::sqrt encountered 3 time(s)
Unsupported operator aten::cumsum encountered 2 time(s)
Unsupported operator aten::sin encountered 1 time(s)
Unsupported operator aten::cos encountered 1 time(s)
Unsupported operator aten::repeat_interleave encountered 2 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
sam.mask_decoder.iou_token, sam.mask_decoder.mask_tokens, sam.prompt_encoder.mask_downscaling, sam.prompt_encoder.mask_downscaling.0, sam.prompt_encoder.mask_downscaling.1, sam.prompt_encoder.mask_downscaling.2, sam.prompt_encoder.mask_downscaling.3, sam.prompt_encoder.mask_downscaling.4, sam.prompt_encoder.mask_downscaling.5, sam.prompt_encoder.mask_downscaling.6, sam.prompt_encoder.no_mask_embed, sam.prompt_encoder.not_a_point_embed, sam.prompt_encoder.point_embeddings.0, sam.prompt_encoder.point_embeddings.1, sam.prompt_encoder.point_embeddings.2, sam.prompt_encoder.point_embeddings.3
FLOPs:  821587372992.0
| name                                          | #elements or shape   |
|:----------------------------------------------|:---------------------|
| model                                         | 0.6G                 |
|  sam                                          |  0.6G                |
|   sam.image_encoder                           |   0.6G               |
|    sam.image_encoder.pos_embed                |    (1, 32, 32, 1280) |
|    sam.image_encoder.patch_embed              |    1.0M              |
|    sam.image_encoder.blocks                   |    0.6G              |
|    sam.image_encoder.neck                     |    0.9M              |
|   sam.prompt_encoder                          |   6.2K               |
|    sam.prompt_encoder.point_embeddings        |    1.0K              |
|    sam.prompt_encoder.not_a_point_embed       |    0.3K              |
|    sam.prompt_encoder.mask_downscaling        |    4.7K              |
|    sam.prompt_encoder.no_mask_embed           |    0.3K              |
|   sam.mask_decoder                            |   3.9M               |
|    sam.mask_decoder.transformer               |    3.3M              |
|    sam.mask_decoder.iou_token                 |    0.3K              |
|    sam.mask_decoder.mask_tokens               |    0.8K              |
|    sam.mask_decoder.output_upscaling          |    74.0K             |
|    sam.mask_decoder.output_hypernetworks_mlps |    0.4M              |
|    sam.mask_decoder.iou_prediction_head       |    0.1M              |